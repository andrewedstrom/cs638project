{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ignore scikit learn deprication warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/andrew/workspace/endangeredanimals/learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#os.chdir('../blocking/')\n",
    "import pandas as pd\n",
    "import py_entitymatching as em\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(281, 5)\n"
     ]
    }
   ],
   "source": [
    "from numpy import genfromtxt\n",
    "# train = pd.read_csv('train_reduced.csv', encoding=\"ISO-8859-1\", index_col='_id')\n",
    "# test = pd.read_csv('test_reduced.csv', encoding=\"ISO-8859-1\", index_col='_id')\n",
    "from numpy import genfromtxt\n",
    "#myData = genfromtxt('train.csv',delimiter=',')\n",
    "\n",
    "#train = genfromtxt('train_reduced_CME_test.csv',delimiter=',')\n",
    "#test = genfromtxt('test_reduced_CME_test.csv',delimiter=',')\n",
    "\n",
    "train = genfromtxt('train_reduced.csv',delimiter=',')\n",
    "test = genfromtxt('test_reduced.csv',delimiter=',')\n",
    "\n",
    "print(train.shape)\n",
    "# test = test.dropna()\n",
    "# test.target\n",
    "train = train[~np.isnan(train).any(axis=1)]\n",
    "\n",
    "y = train[:,4] # label\n",
    "X = train[:,0:3] # data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# # TODO use F-1 for scoring, or a hybrid if possible\n",
    "# # we can use a for loop ['f1', 'accuracy', ]\n",
    "# # http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "# # logistic regression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# logreg = LogisticRegression()\n",
    "# logreg.fit(X,y)\n",
    "# print('Logistic Regression:')\n",
    "# print(, cross_val_score(logreg, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # decision tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# clf = DecisionTreeClassifier()\n",
    "# clf.fit(X,y)\n",
    "# print('Decision Tree:', cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # random forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# forest = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
    "# forest.fit(X,y)\n",
    "# print('Random Forest:', cross_val_score(forest, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # support vector machine\n",
    "# from sklearn.svm import LinearSVC\n",
    "# svm = LinearSVC()\n",
    "# svm.fit(X,y)\n",
    "# print('SVM:', cross_val_score(svm, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # naive bayes\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnb = GaussianNB()\n",
    "# gnb.fit(X,y)\n",
    "# print('Naive Bayes:', cross_val_score(svm, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # KNN\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knn = KNeighborsClassifier(n_neighbors=20)\n",
    "# knn.fit(X,y)\n",
    "# print('KNN:', cross_val_score(knn, X, y, cv=10, scoring='accuracy').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Awesome sauce.  Now let's fill in missing values rather than dropping them\n",
    "# reload train\n",
    "train = genfromtxt('train_reduced_CME_test.csv',delimiter=',')\n",
    "# print(train.shape)\n",
    "\n",
    "# get rid of first row (I think this is just column labels)\n",
    "train = train[1:,:]\n",
    "\n",
    "# replace missing featureVals with 0.5 (halfway in between)\n",
    "where_are_NaNs = np.isnan(train)\n",
    "train[where_are_NaNs] = -1\n",
    "\n",
    "y = train[:,4] # label\n",
    "X = train[:,0:3] # data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "# #TODO use F-1 for scoring, or a hybrid if possible\n",
    "\n",
    "# # logistic regression\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# logregFillNA = LogisticRegression()\n",
    "# logregFillNA.fit(X,y)\n",
    "# print('Logistic Regression:', cross_val_score(logregFillNA, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # decision tree\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# dtFillNA = DecisionTreeClassifier()\n",
    "# dtFillNA.fit(X,y)\n",
    "# print('Decision Tree:', cross_val_score(dtFillNA, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # random forest\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# forestFillNA = RandomForestClassifier(n_estimators=10, max_depth=10)\n",
    "# forestFillNA.fit(X,y)\n",
    "# print('Random Forest:', cross_val_score(forestFillNA, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # support vector machine\n",
    "# from sklearn.svm import LinearSVC\n",
    "# svmFillNA = LinearSVC()\n",
    "# svmFillNA.fit(X,y)\n",
    "# print('SVM:', cross_val_score(svmFillNA, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # naive bayes\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# gnbFillNA = GaussianNB()\n",
    "# gnbFillNA.fit(X,y)\n",
    "# print('Naive Bayes:', cross_val_score(gnbFillNA, X, y, cv=10, scoring='accuracy').mean())\n",
    "\n",
    "# # KNN\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# knnFillNA = KNeighborsClassifier(n_neighbors=20)\n",
    "# knnFillNA.fit(X,y)\n",
    "# print('KNN:', cross_val_score(knnFillNA, X, y, cv=10, scoring='accuracy').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "accuracy: 0.868144499179\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "\n",
      "Decision Tree:\n",
      "accuracy: 0.885905856596\n",
      "precision: 0.641666666667\n",
      "recall: 0.441666666667\n",
      "f1: 0.516428571429\n",
      "\n",
      "Random Forest:\n",
      "accuracy: 0.896506112023\n",
      "precision: 0.766666666667\n",
      "recall: 0.441666666667\n",
      "f1: 0.509047619048\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.646524356869\n",
      "precision: 0.0249042145594\n",
      "recall: 0.5\n",
      "f1: 0.0\n",
      "\n",
      "Naive Bayes:\n",
      "accuracy: 0.868144499179\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "\n",
      "KNN:\n",
      "accuracy: 0.868144499179\n",
      "precision: 0.0\n",
      "recall: 0.0\n",
      "f1: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "          DecisionTreeClassifier(), \n",
    "          RandomForestClassifier(n_estimators=10, max_depth=10),\n",
    "          LinearSVC(),\n",
    "          GaussianNB(),\n",
    "          KNeighborsClassifier(n_neighbors=20)\n",
    "         ]\n",
    "names =  ['Logistic Regression', \n",
    "          'Decision Tree',\n",
    "          'Random Forest',\n",
    "          'SVM',\n",
    "          'Naive Bayes',\n",
    "          'KNN']\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "def compute_metrics(name, model):\n",
    "    model.fit(X,y)\n",
    "    print(\"{}:\".format(name))\n",
    "    for metric in metrics:\n",
    "        print(metric + ':', cross_val_score(model, X, y, cv=10, scoring=metric).mean())\n",
    "    print('')\n",
    "\n",
    "for i in range(len(names)):\n",
    "    compute_metrics(names[i], models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
