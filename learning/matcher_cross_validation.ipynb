{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Ignore scikit learn deprication warnings\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tammi/Desktop/CS 638 Stuffs/cs638project/learning\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "#os.chdir('../blocking/')\n",
    "import pandas as pd\n",
    "import py_entitymatching as em\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import style\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "# train = pd.read_csv('train_reduced.csv', encoding=\"ISO-8859-1\", index_col='_id')\n",
    "# test = pd.read_csv('test_reduced.csv', encoding=\"ISO-8859-1\", index_col='_id')\n",
    "from numpy import genfromtxt\n",
    "#myData = genfromtxt('train.csv',delimiter=',')\n",
    "\n",
    "#train = genfromtxt('train_reduced_CME_test.csv',delimiter=',')\n",
    "#test = genfromtxt('test_reduced_CME_test.csv',delimiter=',')\n",
    "\n",
    "train = genfromtxt('train_reduced.csv',delimiter=',')\n",
    "test = genfromtxt('test_reduced.csv',delimiter=',')\n",
    "\n",
    "#print(train.shape)\n",
    "# test = test.dropna()\n",
    "# test.target\n",
    "train = train[~np.isnan(train).any(axis=1)]\n",
    "\n",
    "y = train[:,4] # label\n",
    "X = train[:,0:3] # data\n",
    "#print(X)\n",
    "#print(y)\n",
    "#print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 19)\n",
      "[  8.16009400e+06   1.96078431e-01   2.85714286e-01   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   4.63296703e-01   2.10000000e+01\n",
      "   1.60000000e-01  -8.00000000e+00   3.00000000e+00   1.00000000e+00\n",
      "   1.00000000e+00   0.00000000e+00   1.00000000e+00   1.00000000e+00\n",
      "   0.00000000e+00   1.00000000e+00   0.00000000e+00]\n",
      "0.0\n",
      "X!\n",
      "(124, 17)\n",
      "y\n",
      "(124,)\n",
      "0.0\n",
      "X\n",
      "(124, 17)\n",
      "[  0.19607843   0.28571429   0.           0.           0.           0.4632967\n",
      "  21.           0.16        -8.           3.           1.           1.           0.\n",
      "   1.           1.           0.           1.        ]\n"
     ]
    }
   ],
   "source": [
    "# Awesome sauce.  Now let's fill in missing values rather than dropping them\n",
    "# reload train\n",
    "train = genfromtxt('train_reduced.csv',delimiter=',')\n",
    "\n",
    "# get rid of first row (I think this is just column labels)\n",
    "train = train[1:,:]\n",
    "\n",
    "# # # replace missing featureVals with 0.5 (halfway in between)\n",
    "# where_are_NaNs = np.isnan(train)\n",
    "# train[where_are_NaNs] = 0\n",
    "\n",
    "\n",
    "##Drop all nans:\n",
    "train = train[~np.isnan(train).any(axis=1)]\n",
    "\n",
    "\n",
    "print(train.shape)\n",
    "print(train[6,:])\n",
    "print\n",
    "print(train[6,train.shape[1]-1])\n",
    "len(train)\n",
    "\n",
    "y = train[:,train.shape[1]-1] # label\n",
    "X = train[:,1:train.shape[1]-1]  # data\n",
    "print('X!')\n",
    "print(X.shape)\n",
    "\n",
    "print('y')\n",
    "print(y.shape)\n",
    "print(y[6])\n",
    "print('X')\n",
    "print(X.shape)\n",
    "print(X[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MLPClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6fbe7fb14699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MLPClassifier'"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import *\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import *\n",
    "\n",
    "models = [LogisticRegression(), \n",
    "          DecisionTreeClassifier(), \n",
    "          RandomForestClassifier(n_estimators=15, max_depth=15),\n",
    "          LinearSVC(),\n",
    "          SVC(),\n",
    "          GaussianNB(),\n",
    "          KNeighborsClassifier(n_neighbors=20),\n",
    "          MLPClassifier(solver='lbfgs', alpha=0.001,  hidden_layer_sizes=(8, 6))\n",
    "\n",
    "         ]\n",
    "names =  ['Logistic Regression', \n",
    "          'Decision Tree',\n",
    "          'Random Forest',\n",
    "          'LinearSVC',\n",
    "          'SVC',\n",
    "          'Naive Bayes',\n",
    "          'KNN',\n",
    "          'MLP'\n",
    "         ]\n",
    "\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1'] # 'accuracy', \n",
    "\n",
    "def compute_metrics(name, model):\n",
    "    model.fit(X,y)\n",
    "    print(\"{}:\".format(name))\n",
    "    for metric in metrics:\n",
    "        print(metric + ':', cross_val_score(model, X, y, cv=10, scoring=metric).mean())\n",
    "    print('')\n",
    "\n",
    "for i in range(len(names)):\n",
    "    compute_metrics(names[i], models[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CME's grid search stuff\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# random forest\n",
    "max_features = np.arange(1,19,4)\n",
    "min_samples_split = np.arange(1,11,4)\n",
    "min_samples_leaf = np.arange(1,11,4)\n",
    "n_estimators = np.arange(15,26,4)\n",
    "clf = RandomForestClassifier()\n",
    "param_grid = {\"max_depth\": [3,6,9, None],\n",
    "              \"n_estimators\": n_estimators,\n",
    "              \"max_features\": max_features,\n",
    "              \"min_samples_split\": min_samples_split,\n",
    "              \"min_samples_leaf\": min_samples_leaf,\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid,scoring='f1',cv=10)\n",
    "grid_search.fit(X, y)\n",
    "print(\"randForest:\" + str(grid_search.best_score_))\n",
    "print(\"randForest:\" + str(grid_search.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Decision tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "param_grid = {\"max_depth\": [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19, None]}\n",
    "DTC = DecisionTreeClassifier()\n",
    "\n",
    "# run grid search\n",
    "grid_search_ABC = GridSearchCV(DTC, param_grid=param_grid, cv=10,scoring = 'f1')\n",
    "grid_search_ABC.fit(X, y)\n",
    "print(\"DT: \" + str(grid_search_ABC.best_score_))\n",
    "print(\"Best estimator: \" + str(grid_search_ABC.best_estimator_))\n",
    "\n",
    "\n",
    "\n",
    "# KNN tuning\n",
    "knn = KNeighborsClassifier()\n",
    "k_range = np.arange(1,50)\n",
    "param_grid = dict(n_neighbors=k_range)\n",
    "gridKNN = GridSearchCV(knn, param_grid, cv=10, scoring='f1')\n",
    "gridKNN.fit(X,y)\n",
    "print(\"KNN:\" + str(gridKNN.best_score_)\n",
    "print(\"KNN:\" + str(gridKNN.best_estimator_)\n",
    "\n",
    "\n",
    "# SVC tuning\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=10,\n",
    "                       scoring='f1')\n",
    "clf.fit(X,y)\n",
    "print(\"SVC:\" + str(clf.best_score_)\n",
    "print(\"SVC:\" + str(clf.best_estimator_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MLP\n",
    "from itertools import product\n",
    "tuned_parameters = {'solver': ['lbfgs'],\n",
    "                    'alpha': [1e-3,1e-4],\n",
    "                    'hidden_layer_sizes': list(product(list(range(2,15)), repeat=1)) + list(product(list(range(3,9)),repeat=2))} \n",
    "clf = GridSearchCV(MLPClassifier(), tuned_parameters, cv=5,\n",
    "                       scoring='f1')\n",
    "clf.fit(X,y)\n",
    "print(clf.best_score_)\n",
    "compute_metrics('MLP', clf.best_estimator_)\n",
    "print(clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
